# Quick Start Guide

Get up and running with the Vector + Graph Database in 5 minutes!

## üöÄ Installation (2 minutes)

### Step 1: Install Dependencies
```bash
pip install -r requirements.txt
```

This installs:
- FastAPI, Streamlit (web frameworks)
- sentence-transformers (embeddings)
- faiss-cpu (vector search)
- rank-bm25 (keyword search)
- SQLite (built into Python)

### Step 2: Start the System

**Option A - Linux/Mac:**
```bash
chmod +x start.sh
./start.sh
```

**Option B - Windows:**
```bash
start.bat
```

**Option C - Manual:**
```bash
# Terminal 1: Start backend
python app.py

# Terminal 2: Start UI  
streamlit run streamlit_app.py
```

### Step 3: Open Your Browser
- UI: http://localhost:8501
- API: http://localhost:8000
- Docs: http://localhost:8000/docs

## üìù First Steps (3 minutes)

### 1. Load Sample Data
1. Go to the "üìä Upload Data" tab
2. Click "üöÄ Load Sample Knowledge Graph"
3. Wait 10 seconds for data creation

This creates a knowledge graph about AI, databases, and programming with 8 nodes and 11 relationships.

### 2. Try Vector Search
1. Go to "üîç Vector Search" tab
2. Search for: `"machine learning and neural networks"`
3. See semantically similar results ranked by relevance

### 3. Try Graph Search
1. Go to "üï∏Ô∏è Graph Search" tab
2. Copy any node ID from previous search
3. Set depth to 2
4. See connected nodes through relationships

### 4. Try Hybrid Search ‚≠ê
1. Go to "‚ö° Hybrid Search" tab
2. Search for: `"artificial intelligence systems"`
3. Set Vector+Keyword weight: 0.7
4. Set Graph weight: 0.3
5. Optionally paste a start node ID
6. See how RRF combines all methods!

## üéØ Understanding the Results

### Vector Search
```
Query: "machine learning"
Result #1 [Score: 0.87]
  "Machine learning enables computers to learn..."
```
- High score = semantically similar
- Finds meaning, not just keywords

### Graph Search
```
Start: node-1234
Distance 1: "Deep learning uses neural networks..."
Distance 2: "Natural language processing enables..."
```
- Distance = number of edges away
- Discovers related concepts

### Hybrid Search (Best!)
```
Result #1 [Final: 0.92 | Vector: 0.85 | Graph: 0.75]
  "Machine learning is a subset of AI..."
```
- **Final Score**: Weighted combination via RRF
- **Vector Score**: Semantic + keyword (RRF-fused)
- **Graph Score**: Relationship proximity
- Best of all worlds!

## üîß API Examples

### Create a Node
```bash
curl -X POST http://localhost:8000/nodes \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Transformers revolutionized NLP",
    "metadata": {"topic": "AI"},
    "auto_embed": true
  }'
```

### Create an Edge
```bash
curl -X POST http://localhost:8000/edges \
  -H "Content-Type: application/json" \
  -d '{
    "source": "node-1234.56",
    "target": "node-7890.12",
    "type": "related_to",
    "weight": 1.0
  }'
```

### Search
```bash
# Vector search
curl -X POST http://localhost:8000/search/vector \
  -H "Content-Type: application/json" \
  -d '{"query_text": "AI and ML", "top_k": 5}'

# Hybrid search
curl -X POST http://localhost:8000/search/hybrid \
  -H "Content-Type: application/json" \
  -d '{
    "query_text": "AI systems",
    "vector_weight": 0.7,
    "graph_weight": 0.3,
    "top_k": 10
  }'
```

## üé¨ Run the Demo Script

For a guided walkthrough:
```bash
python demo.py
```

This creates a complete knowledge graph and demonstrates:
- Vector search
- Graph traversal  
- Hybrid search with RRF
- Comparison of all methods

## üí° Tips

### Best Practices

1. **Always use hybrid search** for best results
   - Vector+Keyword weight: 0.6-0.8 for semantic queries
   - Graph weight: 0.2-0.4 for relationship context

2. **Create rich graphs** for better graph search
   - Add meaningful edge types
   - Connect related concepts
   - Build hierarchies

3. **Use metadata** for filtering (future feature)
   - Categories, tags, timestamps
   - Domain-specific attributes

### Weight Tuning

| Query Type | Vector+Keyword | Graph | Reason |
|------------|----------------|-------|--------|
| Semantic questions | 0.8-0.9 | 0.1-0.2 | Prioritize meaning |
| Known relationships | 0.3-0.4 | 0.6-0.7 | Prioritize structure |
| Balanced discovery | 0.5-0.6 | 0.4-0.5 | Equal importance |

### Common Issues

**"Cannot connect to backend"**
- Make sure `python app.py` is running
- Check port 8000 is not in use

**"No results found"**
- Load sample data first
- Check your query spelling
- Try broader search terms

**"Import errors"**
- Run `pip install -r requirements.txt`
- Make sure Python 3.8+

## üèÜ Demo Storyline for Judges

### 1. Introduction (30 seconds)
"We built a Vector + Graph hybrid database that uses Reciprocal Rank Fusion to combine semantic search, keyword matching, and graph relationships for superior retrieval."

### 2. Show Vector Search (1 minute)
- Query: "machine learning algorithms"
- Show semantic matches without exact keywords
- Point out: "Finds *meaning*, not just words"

### 3. Show Graph Search (1 minute)
- Start from ML node
- Show connected concepts at depth 2
- Point out: "Discovers relationships and context"

### 4. Show Hybrid Search ‚≠ê (2 minutes)
- Same query: "machine learning algorithms"
- Adjust weights in real-time
- Show score breakdown
- Point out: "RRF combines both methods optimally"

### 5. Compare Results (1 minute)
- Side-by-side: Vector vs Graph vs Hybrid
- Highlight how hybrid catches what others miss
- Show the final score formula

### 6. Technical Deep-Dive (1 minute)
- Open `/docs` endpoint
- Show architecture diagram
- Mention: RRF (industry standard), FAISS, BM25, sentence-transformers

### 7. Closing (30 seconds)
"Our system combines the best of vector, keyword, and graph search using proven algorithms. It's fast, accurate, and ready for real-world use."

## üìö Next Steps

1. **Explore the code**: `app.py` is well-documented
2. **Read architecture**: `ARCHITECTURE.md` explains everything
3. **Try your own data**: Upload JSON via the UI
4. **Experiment with weights**: Find optimal settings for your use case
5. **Check API docs**: http://localhost:8000/docs for interactive testing

## üéì Learn More

- **RRF Algorithm**: See `ARCHITECTURE.md` section on Reciprocal Rank Fusion
- **Best Practices**: Check the `README.md` for detailed usage
- **API Reference**: Interactive docs at `/docs` endpoint

## ‚ùì FAQ

**Q: Why is it called "hybrid"?**  
A: Combines 3 methods: vector similarity, keyword matching (BM25), and graph traversal.

**Q: What is RRF?**  
A: Reciprocal Rank Fusion - an algorithm that intelligently merges rankings from multiple search methods. Used by Azure, Weaviate, Pinecone.

**Q: Why not use OpenAI embeddings?**  
A: We use local embeddings (sentence-transformers) to ensure the system runs entirely offline with no API costs.

**Q: Can it scale?**  
A: Current setup handles 10K nodes easily. For larger scales, upgrade to HNSW index and PostgreSQL (see `ARCHITECTURE.md`).

**Q: How accurate is it?**  
A: The combination of semantic, keyword, and graph methods via RRF typically outperforms single-method approaches by 15-30% (see industry benchmarks).

---

**Ready to impress the judges?** You now have a production-ready hybrid retrieval system! üöÄ